{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa33134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides ways to work with large multidimensional arrays\n",
    "import numpy as np \n",
    "# Allows for further data manipulation and analysis\n",
    "import pandas as pd\n",
    "from pandas_datareader import data # Reads stock data \n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import matplotlib.dates as mdates # Styling dates\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt # For defining dates\n",
    "# import mplfinance as mpf # Matplotlib finance\n",
    "\n",
    "import time\n",
    "\n",
    "# Used to get data from a directory\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#Statsmodels is a great library we can use to run regressions.\n",
    "import statsmodels.api as sm\n",
    "# Seaborn extends the capabilities of Matplotlib\n",
    "import seaborn as sns\n",
    "# Used for calculating regressions\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a276eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the tickers here according to what's in the portfolio\n",
    "tickers = ['HSON','ISSC','KRNT','RCII','SAIA','AMD','EPAM','ASML',\n",
    "          'AUDC','DSGX','MGIC','DHI','LULU','MBUU','MCRI','RUSHA',\n",
    "          'CTLT','IDXX','BDSI','MEDP','MODV','RGEN','TROW','CG',\n",
    "          'TBBK','FCX','NUE','SBAC','COP','QNST','TTGT','^FVX']\n",
    "\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2022-01-01'\n",
    "\n",
    "panel_data = data.DataReader(tickers,'yahoo', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3d4af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1259 entries, 2017-01-03 to 2021-12-31\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   HSON    1259 non-null   float64\n",
      " 1   ISSC    1259 non-null   float64\n",
      " 2   KRNT    1259 non-null   float64\n",
      " 3   RCII    1259 non-null   float64\n",
      " 4   SAIA    1259 non-null   float64\n",
      " 5   AMD     1259 non-null   float64\n",
      " 6   EPAM    1259 non-null   float64\n",
      " 7   ASML    1259 non-null   float64\n",
      " 8   AUDC    1259 non-null   float64\n",
      " 9   DSGX    1259 non-null   float64\n",
      " 10  MGIC    1259 non-null   float64\n",
      " 11  DHI     1259 non-null   float64\n",
      " 12  LULU    1259 non-null   float64\n",
      " 13  MBUU    1259 non-null   float64\n",
      " 14  MCRI    1259 non-null   float64\n",
      " 15  RUSHA   1259 non-null   float64\n",
      " 16  CTLT    1259 non-null   float64\n",
      " 17  IDXX    1259 non-null   float64\n",
      " 18  BDSI    1259 non-null   float64\n",
      " 19  MEDP    1259 non-null   float64\n",
      " 20  MODV    1259 non-null   float64\n",
      " 21  RGEN    1259 non-null   float64\n",
      " 22  TROW    1259 non-null   float64\n",
      " 23  CG      1259 non-null   float64\n",
      " 24  TBBK    1259 non-null   float64\n",
      " 25  FCX     1259 non-null   float64\n",
      " 26  NUE     1259 non-null   float64\n",
      " 27  SBAC    1259 non-null   float64\n",
      " 28  COP     1259 non-null   float64\n",
      " 29  QNST    1259 non-null   float64\n",
      " 30  TTGT    1259 non-null   float64\n",
      " 31  ^FVX    1259 non-null   float64\n",
      "dtypes: float64(32)\n",
      "memory usage: 324.6 KB\n"
     ]
    }
   ],
   "source": [
    "#check that all stocks have the same amount of data otherwise change the date range\n",
    "\n",
    "adj_close = panel_data['Close']\n",
    "adj_close.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319d3ec",
   "metadata": {},
   "source": [
    "## Function that saves dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b45faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_csv(kind, df, ticker):\n",
    "    df.to_csv(kind + ticker + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54578537",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    panel_data = data.DataReader(ticker,'yahoo', start_date, end_date)\n",
    "#     close = panel_data['Close']\n",
    "    adj_close = panel_data['Close']\n",
    "    save_dataframe_to_csv('close', adj_close, ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23550c",
   "metadata": {},
   "source": [
    "## Function that returns dataframe from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7813fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_csv(kind, ticker):\n",
    "    try:\n",
    "        df = pd.read_csv(kind + ticker + '.csv', index_col='Date', \n",
    "                         parse_dates=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        # print(\"File Doesn't Exist\")\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfa21c",
   "metadata": {},
   "source": [
    "## Add Daily Return to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_daily_return_to_df(kind, df, ticker):\n",
    "    df['daily_return'] = (df['Close'] / df['Close'].shift(1)) - 1\n",
    "    # Save data to a CSV file\n",
    "    save_dataframe_to_csv(kind, df, ticker)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58358b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    df = get_df_from_csv('close', ticker)\n",
    "    add_daily_return_to_df('close', df, ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8949ca",
   "metadata": {},
   "source": [
    "## Merge multiple stocks in one dataframe by col name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_by_column_name(col_name, sdate, edate, *tickers):\n",
    "    # Will hold data for all dataframes with the same column name\n",
    "    mult_df = pd.DataFrame()\n",
    "    \n",
    "    for x in tickers:\n",
    "        df = get_df_from_csv('close', x)\n",
    "    \n",
    "        # NEW Check if your dataframe has duplicate indexes\n",
    "        if not df.index.is_unique:\n",
    "            # Delete duplicates \n",
    "            df = df.loc[~df.index.duplicated(), :]\n",
    "        \n",
    "        mask = (df.index >= sdate) & (df.index <= edate)\n",
    "        mult_df[x] = df.loc[mask][col_name]\n",
    "        \n",
    "    return mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c3f92",
   "metadata": {},
   "source": [
    "## Get stock prices on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_on_date(stocks_df, date):\n",
    "    return stocks_df.loc[pd.DatetimeIndex([date])]['Close'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c8443",
   "metadata": {},
   "source": [
    "## Returns the value of portfolio by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56289d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_val_by_date(date, shares, tickers):\n",
    "    port_prices = merge_df_by_column_name('Close',  date, date, *port_list)\n",
    "    # Convert from dataframe to Python list\n",
    "    port_prices = port_prices.values.tolist()\n",
    "    # Trick that converts a list of lists into a single list\n",
    "    port_prices = sum(port_prices, [])\n",
    "    \n",
    "    # Create a list of values by multiplying shares by price\n",
    "    value_list = []\n",
    "    for price, share in zip(port_prices, shares):\n",
    "        value_list.append(price * share)\n",
    "    \n",
    "    return sum(value_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0bbdf5",
   "metadata": {},
   "source": [
    "## Find Daily Return for Whole Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf49f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_daily_return(sdate, edate, shares, tickers):\n",
    "    # Merge all daily prices for all stocks into 1 dataframe\n",
    "    mult_df = merge_df_by_column_name('Close',  sdate, \n",
    "                                  edate, *port_list)\n",
    "    \n",
    "    # Get the number of stocks in portfolio\n",
    "    num_cols = len(mult_df.columns)\n",
    "    \n",
    "    # Multiply each stock column by the number of shares\n",
    "    i = 0\n",
    "    while i < num_cols:\n",
    "        mult_df[tickers[i]] = mult_df[tickers[i]].apply(lambda x: x * shares[i])\n",
    "        i += 1\n",
    "        \n",
    "    # Create a new column with the sums of all stocks named Total\n",
    "    mult_df['Total'] = mult_df.iloc[:, 0:num_cols].sum(axis=1)\n",
    "    \n",
    "    # Add column for portfolio daily return\n",
    "    mult_df['daily_return'] = (mult_df['Total'] / mult_df['Total'].shift(1)) - 1\n",
    "    \n",
    "    return mult_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to the list of stocks we using\n",
    "port_list = ['HSON','ISSC','KRNT','RCII','SAIA','AMD','EPAM','ASML',\n",
    "          'AUDC','DSGX','MGIC','DHI','LULU','MBUU','MCRI','RUSHA',\n",
    "          'CTLT','IDXX','BDSI','MEDP','MODV','RGEN','TROW','CG',\n",
    "          'TBBK','FCX','NUE','SBAC','COP','QNST','TTGT','^FVX']\n",
    "\n",
    "#add in the weightage of stocks\n",
    "port_shares = [0.008618,0.003478667,0.01438,0.008773333,0.031416667,\n",
    "              0.007651333,0.016572667,0.017943333,0.010706,0.009872667,\n",
    "              0.003921333,0.012,0.037236667,0.00684,0.001423333,0.009167333,\n",
    "              0.000710667,0.024792,0.004878,0.006279333,0.006434,0.023572667,\n",
    "              0.019544,0.027532,0.019590667,0.018427333,0.048239333,0.066666667,\n",
    "              0.066666667,0.005342,0.061324667,0.4]\n",
    "\n",
    "# tot_port_df = get_port_daily_return('2020-01-02', '2020-12-31', \n",
    "#                                     port_shares, port_list)\n",
    "\n",
    "#change the dates according to what you put on top\n",
    "tot_port_df = get_port_daily_return('2017-01-01', '2022-01-01', port_shares, port_list)\n",
    "tot_port_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccccca0",
   "metadata": {},
   "source": [
    "## Get old data for portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the dates according to what you put on top\n",
    "tot_port_df = get_port_daily_return('2017-01-01', '2022-01-01', \n",
    "                                    port_shares, port_list)\n",
    "tot_port_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089ecc3",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6871ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_port_df = tot_port_df.asfreq('d')\n",
    "tot_port_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete NaNs for nontrading days\n",
    "tot_port_df = tot_port_df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce7f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_port_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all unneeded columns - basically delete all except Total\n",
    "del_col = ['HSON','ISSC','KRNT','RCII','SAIA','AMD','EPAM','ASML',\n",
    "          'AUDC','DSGX','MGIC','DHI','LULU','MBUU','MCRI','RUSHA',\n",
    "          'CTLT','IDXX','BDSI','MEDP','MODV','RGEN','TROW','CG',\n",
    "          'TBBK','FCX','NUE','SBAC','COP','QNST','TTGT','^FVX', \"daily_return\"]\n",
    "\n",
    "for x in del_col:\n",
    "    tot_port_df = tot_port_df.drop([x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_port_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for seaborn plot\n",
    "sns.set_style('darkgrid')\n",
    "# Add automatic datetime converters\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "# Default figure size\n",
    "sns.mpl.rc('figure',figsize=(19, 13))\n",
    "\n",
    "# Set fig and ax\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Figure out optimum lags for this data set\n",
    "lags = ar_select_order(tot_port_df, maxlag=30)\n",
    "print(\"Lags :\", lags.ar_lags)\n",
    "\n",
    "# Create our model using whole data set\n",
    "model = AutoReg(tot_port_df['Total'], lags.ar_lags)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Define training and testing area\n",
    "print(\"Observations :\", len(tot_port_df)) # 1095 observations\n",
    "\n",
    "train_df = tot_port_df.iloc[0:1459] # First 80% \n",
    "test_df = tot_port_df.iloc[1459:] # Last 20%\n",
    "\n",
    "# Define training model for 459 days (Play with Number & Test)\n",
    "# and White's covariance estimator\n",
    "train_model = AutoReg(tot_port_df['Total'], 459).fit(cov_type=\"HC0\")\n",
    "\n",
    "# # Define start and end for prediction \n",
    "start = len(train_df)\n",
    "end = len(train_df) + len(test_df) - 1\n",
    "\n",
    "prediction = train_model.predict(start=start, end=end, dynamic=True)\n",
    "\n",
    "# Plot testing data with prediction\n",
    "ax = test_df.plot(ax=ax) # blue\n",
    "ax = prediction.plot(ax=ax) # orange\n",
    "\n",
    "# Predict 60 days into the future\n",
    "forecast = train_model.predict(start=end, end=end+1260, dynamic=True)\n",
    "ax = forecast.plot(ax=ax) # Green"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc39d00",
   "metadata": {},
   "source": [
    "## Calculate annualized returns for forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_series = (1 + forecast_df.pct_change()).cumprod() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d96d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "return_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate annualized volatility\n",
    "annualized_vol = np.sqrt(np.log(forecast / forecast.shift(1)).var()) * np.sqrt(252)\n",
    "annualized_vol*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf5291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99622a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85fb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
